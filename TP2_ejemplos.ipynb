{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplos con BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto_original</th>\n",
       "      <th>texto_limpio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Para la caída del cabello, tengo un nuevo champú</td>\n",
       "      <td>para la caída del cabello tengo un nuevo champú</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Los hámsters comen zanahorias</td>\n",
       "      <td>los hámsters comen zanahorias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>¿Me podés mandar fotos de la pileta?</td>\n",
       "      <td>me podés mandar fotos de la pileta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hola Cristina que bueno que pueda hablar con vos</td>\n",
       "      <td>hola cristina que bueno que pueda hablar con vos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tranquilo va a estar todo bien</td>\n",
       "      <td>tranquilo va a estar todo bien</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     texto_original  \\\n",
       "0  Para la caída del cabello, tengo un nuevo champú   \n",
       "1                     Los hámsters comen zanahorias   \n",
       "2              ¿Me podés mandar fotos de la pileta?   \n",
       "3  Hola Cristina que bueno que pueda hablar con vos   \n",
       "4                    Tranquilo va a estar todo bien   \n",
       "\n",
       "                                       texto_limpio  \n",
       "0   para la caída del cabello tengo un nuevo champú  \n",
       "1                     los hámsters comen zanahorias  \n",
       "2                me podés mandar fotos de la pileta  \n",
       "3  hola cristina que bueno que pueda hablar con vos  \n",
       "4                    tranquilo va a estar todo bien  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://github.com/LeoBrasileo/Aprendizaje-Automatico-TP2/raw/refs/heads/main/data/datos_google_argento.csv'\n",
    "df_google_arg = pd.read_csv(url, sep=',', index_col=False)\n",
    "df_google_arg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declaramos a nuestro tokenizer como el tokenizer de Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "\n",
    "# Defino el tamaño del vocabulario como el tamaño del vocabulario default de bert-base-multilingual-cased,\n",
    "# Esto se usaría en las capas de embeddings, como dimensión. \n",
    "VOCAB_SIZE = tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'qué', 'hora', 'va', '##mos', 'a', 'm', '##c', '##dona', '##ld', '##s']\n",
      "['¿', 'A', 'qué', 'hora', 'va', '##mos', 'a', 'McDonald', '##s', '?']\n"
     ]
    }
   ],
   "source": [
    "original = '¿A qué hora vamos a McDonalds?'\n",
    "texto = \"a qué hora vamos a mcdonalds\"\n",
    "tokens = tokenizer.tokenize(texto)\n",
    "tokens_orig = tokenizer.tokenize(original)\n",
    "\n",
    "print(tokens)\n",
    "print(tokens_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[169, 38188, 24301, 10321, 13386, 169, 181, 10350, 64674, 12620, 10107]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_tokens_to_ids(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpieza de strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocales_con_acento_min = [chr(x) for x in [ord('á'), ord('é'), ord('í'), ord('ó'), ord('ú')]]\n",
    "vocales_con_acento_may = [chr(x) for x in [ord('Á'), ord('É'), ord('Í'), ord('Ó'), ord('Ú')]]\n",
    "allowed_characters = [chr(x) for x in range(97,123)] + vocales_con_acento_min + [chr(241)] + [chr(10), chr(32)] + [chr(x) for x in range(48,58)] # los caracteres de letras minúsculas, espacio en blanco y fin de linea y números\n",
    "characters_to_replace = [chr(x) for x in range(65,91)] + vocales_con_acento_may + [chr(209)] #las mayúsculas\n",
    "characters_to_replace_with = [chr(x) for x in range(97,123)] + vocales_con_acento_min + [chr(241)] #las minúsculas\n",
    "replace_dict = dict(zip(characters_to_replace, characters_to_replace_with))\n",
    "\n",
    "def limpiar_string (s) :\n",
    "  res = \"\"\n",
    "  for c in s :\n",
    "    if c in allowed_characters :\n",
    "      res += c\n",
    "    elif c in characters_to_replace :\n",
    "      res += replace_dict[c]\n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veamos que pasa si cortamos un árbol ¿Será capaz de entender? El Árbol no sentirá el corte hasta que sea demaisado tarde: al buscar sus raices para nutrir las hojas, sentirá la desesperación de la falta.\n",
      "¡Ósado el talador, que se preocupa más por el calor de su morada que la protección que ofrece el bosque y la protección de todas sus criaturas contra el silencio verdadero!\n",
      "\n",
      "\n",
      "veamos que pasa si cortamos un árbol será capaz de entender el árbol no sentirá el corte hasta que sea demaisado tarde al buscar sus raices para nutrir las hojas sentirá la desesperación de la falta\n",
      "ósado el talador que se preocupa más por el calor de su morada que la protección que ofrece el bosque y la protección de todas sus criaturas contra el silencio verdadero\n"
     ]
    }
   ],
   "source": [
    "test_limpieza = \"Veamos que pasa si cortamos un árbol ¿Será capaz de entender? El Árbol no sentirá el corte hasta que sea demaisado tarde: al buscar sus raices para nutrir las hojas, sentirá la desesperación de la falta.\" + '\\n' + '¡Ósado el talador, que se preocupa más por el calor de su morada que la protección que ofrece el bosque y la protección de todas sus criaturas contra el silencio verdadero!'\n",
    "print(test_limpieza)\n",
    "print('\\n')\n",
    "print(limpiar_string(test_limpieza))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etiquetas para datos de entrada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota**: es un planteo preliminar, imitando cómo nos piden entregar las respuestas, se pueden hacer modificaciones para lo que necesitemos como entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from py.funciones_dataset import asignar_etiquetas_puntuacion, asignar_puntuacion_a_tokens, reconstruir_texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ejemplo 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero definimos puntuación para los tokens\n",
    "\n",
    "Este ejemplo, usando el - , no anda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instancia_id</th>\n",
       "      <th>token</th>\n",
       "      <th>token_id</th>\n",
       "      <th>capitalizacion</th>\n",
       "      <th>puntuacion_inicial</th>\n",
       "      <th>puntuacion_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>cu</td>\n",
       "      <td>10854</td>\n",
       "      <td>1</td>\n",
       "      <td>¿</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>##ánd</td>\n",
       "      <td>101439</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>##o</td>\n",
       "      <td>10133</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>va</td>\n",
       "      <td>10321</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>##mos</td>\n",
       "      <td>13386</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>m</td>\n",
       "      <td>181</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>##c</td>\n",
       "      <td>10350</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>##dona</td>\n",
       "      <td>64674</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>##ld</td>\n",
       "      <td>12620</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>##sell</td>\n",
       "      <td>68915</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>##os</td>\n",
       "      <td>10310</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>10192</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>viene</td>\n",
       "      <td>12266</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>##n</td>\n",
       "      <td>10115</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>entonces</td>\n",
       "      <td>16720</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>dó</td>\n",
       "      <td>82639</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>##nde</td>\n",
       "      <td>11382</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>están</td>\n",
       "      <td>16037</td>\n",
       "      <td>0</td>\n",
       "      <td>¿</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    instancia_id     token  token_id  capitalizacion puntuacion_inicial  \\\n",
       "0              1        cu     10854               1                  ¿   \n",
       "1              1     ##ánd    101439               1                      \n",
       "2              1       ##o     10133               1                      \n",
       "3              1        va     10321               0                      \n",
       "4              1     ##mos     13386               0                      \n",
       "5              1         a       169               0                      \n",
       "6              1         m       181               2                      \n",
       "7              1       ##c     10350               2                      \n",
       "8              1    ##dona     64674               2                      \n",
       "9              1      ##ld     12620               2                      \n",
       "10             1    ##sell     68915               2                      \n",
       "11             1      ##os     10310               2                      \n",
       "12             1        no     10192               0                      \n",
       "13             1     viene     12266               0                      \n",
       "14             1       ##n     10115               0                      \n",
       "15             1  entonces     16720               1                      \n",
       "16             1        dó     82639               2                      \n",
       "17             1     ##nde     11382               2                      \n",
       "18             1     están     16037               0                  ¿   \n",
       "\n",
       "   puntuacion_final  \n",
       "0                    \n",
       "1                    \n",
       "2                    \n",
       "3                    \n",
       "4                    \n",
       "5                    \n",
       "6                    \n",
       "7                    \n",
       "8                    \n",
       "9                    \n",
       "10                   \n",
       "11                   \n",
       "12                   \n",
       "13                   \n",
       "14                .  \n",
       "15                ,  \n",
       "16                   \n",
       "17                   \n",
       "18                   "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto_original = \"¿Cuándo vamos a McDonald's?Ellos no vienen. Entonces, - ¿dónde están?\"\n",
    "\n",
    "texto_limpio = limpiar_string(texto_original)\n",
    "tokens_texto_limpio = tokenizer.tokenize(texto_limpio)\n",
    "\n",
    "puntuacion_tokens = asignar_puntuacion_a_tokens(instancia_original=texto_original,\n",
    "                                                instancia_id=1,\n",
    "                                                instancia_tokens=tokens_texto_limpio)\n",
    "pd.DataFrame.from_dict(puntuacion_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La instancia etiquetada final (con las etiquetas definidas en _ETIQUETA_PUNT_FINAL_ y _ETIQUETA_PUNT_INICIAL_) sería de esta forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instancia_id</th>\n",
       "      <th>token</th>\n",
       "      <th>token_id</th>\n",
       "      <th>capitalizacion</th>\n",
       "      <th>puntuacion_inicial</th>\n",
       "      <th>puntuacion_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>cu</td>\n",
       "      <td>10854</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>##ánd</td>\n",
       "      <td>101439</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>##o</td>\n",
       "      <td>10133</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>va</td>\n",
       "      <td>10321</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>##mos</td>\n",
       "      <td>13386</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>m</td>\n",
       "      <td>181</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>##c</td>\n",
       "      <td>10350</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>##dona</td>\n",
       "      <td>64674</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>##ld</td>\n",
       "      <td>12620</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>##sell</td>\n",
       "      <td>68915</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>##os</td>\n",
       "      <td>10310</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>10192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>viene</td>\n",
       "      <td>12266</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>##n</td>\n",
       "      <td>10115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>entonces</td>\n",
       "      <td>16720</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>dó</td>\n",
       "      <td>82639</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>##nde</td>\n",
       "      <td>11382</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>están</td>\n",
       "      <td>16037</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    instancia_id     token  token_id  capitalizacion  puntuacion_inicial  \\\n",
       "0              1        cu     10854               1                   1   \n",
       "1              1     ##ánd    101439               1                   0   \n",
       "2              1       ##o     10133               1                   0   \n",
       "3              1        va     10321               0                   0   \n",
       "4              1     ##mos     13386               0                   0   \n",
       "5              1         a       169               0                   0   \n",
       "6              1         m       181               2                   0   \n",
       "7              1       ##c     10350               2                   0   \n",
       "8              1    ##dona     64674               2                   0   \n",
       "9              1      ##ld     12620               2                   0   \n",
       "10             1    ##sell     68915               2                   0   \n",
       "11             1      ##os     10310               2                   0   \n",
       "12             1        no     10192               0                   0   \n",
       "13             1     viene     12266               0                   0   \n",
       "14             1       ##n     10115               0                   0   \n",
       "15             1  entonces     16720               1                   0   \n",
       "16             1        dó     82639               2                   0   \n",
       "17             1     ##nde     11382               2                   0   \n",
       "18             1     están     16037               0                   1   \n",
       "\n",
       "    puntuacion_final  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  \n",
       "5                  0  \n",
       "6                  0  \n",
       "7                  0  \n",
       "8                  0  \n",
       "9                  0  \n",
       "10                 0  \n",
       "11                 0  \n",
       "12                 0  \n",
       "13                 0  \n",
       "14                 2  \n",
       "15                 3  \n",
       "16                 0  \n",
       "17                 0  \n",
       "18                 0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_etiquetados = asignar_etiquetas_puntuacion(puntuacion_tokens)\n",
    "pd.DataFrame.from_dict(tokens_etiquetados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ejemplo 2:\n",
    "\n",
    "Este ejemplo anda, eliminando el -. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instancia_id</th>\n",
       "      <th>token</th>\n",
       "      <th>token_id</th>\n",
       "      <th>capitalizacion</th>\n",
       "      <th>puntuacion_inicial</th>\n",
       "      <th>puntuacion_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>cu</td>\n",
       "      <td>10854</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>##ánd</td>\n",
       "      <td>101439</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>##o</td>\n",
       "      <td>10133</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>va</td>\n",
       "      <td>10321</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>##mos</td>\n",
       "      <td>13386</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>169</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>m</td>\n",
       "      <td>181</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>##c</td>\n",
       "      <td>10350</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>##dona</td>\n",
       "      <td>64674</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>##ld</td>\n",
       "      <td>12620</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>##s</td>\n",
       "      <td>10107</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>ellos</td>\n",
       "      <td>16169</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>10192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>viene</td>\n",
       "      <td>12266</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>##n</td>\n",
       "      <td>10115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>entonces</td>\n",
       "      <td>16720</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>dó</td>\n",
       "      <td>82639</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>##nde</td>\n",
       "      <td>11382</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>están</td>\n",
       "      <td>16037</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    instancia_id     token  token_id  capitalizacion  puntuacion_inicial  \\\n",
       "0              1        cu     10854               1                   1   \n",
       "1              1     ##ánd    101439               1                   0   \n",
       "2              1       ##o     10133               1                   0   \n",
       "3              1        va     10321               0                   0   \n",
       "4              1     ##mos     13386               0                   0   \n",
       "5              1         a       169               0                   0   \n",
       "6              1         m       181               2                   0   \n",
       "7              1       ##c     10350               2                   0   \n",
       "8              1    ##dona     64674               2                   0   \n",
       "9              1      ##ld     12620               2                   0   \n",
       "10             1       ##s     10107               2                   0   \n",
       "11             1     ellos     16169               1                   0   \n",
       "12             1        no     10192               0                   0   \n",
       "13             1     viene     12266               0                   0   \n",
       "14             1       ##n     10115               0                   0   \n",
       "15             1  entonces     16720               1                   0   \n",
       "16             1        dó     82639               0                   1   \n",
       "17             1     ##nde     11382               0                   0   \n",
       "18             1     están     16037               0                   0   \n",
       "\n",
       "    puntuacion_final  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  \n",
       "5                  0  \n",
       "6                  0  \n",
       "7                  0  \n",
       "8                  0  \n",
       "9                  0  \n",
       "10                 1  \n",
       "11                 0  \n",
       "12                 0  \n",
       "13                 0  \n",
       "14                 2  \n",
       "15                 3  \n",
       "16                 0  \n",
       "17                 0  \n",
       "18                 1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto_original = \"¿Cuándo vamos a McDonald's? Ellos no vienen. Entonces, ¿dónde están?\"\n",
    "\n",
    "texto_limpio = limpiar_string(texto_original)\n",
    "tokens_texto_limpio = tokenizer.tokenize(texto_limpio)\n",
    "\n",
    "puntuacion_tokens = asignar_puntuacion_a_tokens(instancia_original=texto_original,\n",
    "                                                instancia_id=1,\n",
    "                                                instancia_tokens=tokens_texto_limpio)\n",
    "\n",
    "tokens_etiquetados = asignar_etiquetas_puntuacion(puntuacion_tokens)\n",
    "\n",
    "pd.DataFrame.from_dict(tokens_etiquetados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ejemplo 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instancia_id</th>\n",
       "      <th>token</th>\n",
       "      <th>token_id</th>\n",
       "      <th>capitalizacion</th>\n",
       "      <th>puntuacion_inicial</th>\n",
       "      <th>puntuacion_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ve</td>\n",
       "      <td>10323</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>##amos</td>\n",
       "      <td>73983</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>que</td>\n",
       "      <td>10121</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>pasa</td>\n",
       "      <td>26088</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>si</td>\n",
       "      <td>10294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>corta</td>\n",
       "      <td>53134</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>##mos</td>\n",
       "      <td>13386</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>un</td>\n",
       "      <td>10119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>árbol</td>\n",
       "      <td>55220</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>será</td>\n",
       "      <td>23843</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>capaz</td>\n",
       "      <td>31941</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>de</td>\n",
       "      <td>10104</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    instancia_id   token  token_id  capitalizacion  puntuacion_inicial  \\\n",
       "0              1      ve     10323               1                   0   \n",
       "1              1  ##amos     73983               1                   0   \n",
       "2              1     que     10121               0                   0   \n",
       "3              1    pasa     26088               0                   0   \n",
       "4              1      si     10294               0                   0   \n",
       "5              1   corta     53134               0                   0   \n",
       "6              1   ##mos     13386               0                   0   \n",
       "7              1      un     10119               0                   0   \n",
       "8              1   árbol     55220               0                   0   \n",
       "9              1    será     23843               1                   1   \n",
       "10             1   capaz     31941               0                   0   \n",
       "11             1      de     10104               0                   0   \n",
       "\n",
       "    puntuacion_final  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  \n",
       "5                  0  \n",
       "6                  0  \n",
       "7                  0  \n",
       "8                  0  \n",
       "9                  0  \n",
       "10                 0  \n",
       "11                 0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_test_limpieza = tokenizer.tokenize(limpiar_string(test_limpieza))\n",
    "\n",
    "puntuacion_tokens = asignar_puntuacion_a_tokens(instancia_original=test_limpieza,\n",
    "                                                instancia_id=1,\n",
    "                                                instancia_tokens=tokens_test_limpieza)\n",
    "\n",
    "tokens_etiquetados = asignar_etiquetas_puntuacion(puntuacion_tokens)\n",
    "\n",
    "pd.DataFrame.from_dict(tokens_etiquetados).head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase del dataset de 100 Años de Soledad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "funcionaron: 1810 sentences\n",
      "con problemas: 336\n",
      "Index 19: 'Si has de volverte loco, vuélvete tú solo gritó . Pero no trates de inculcar a los niños tus ideas d'... Error: string index out of range\n",
      "Index 28: 'Es el olor del demonio dijo ella. En absoluto corrigió Valeria . Está comprobado que el demonio tien'... Error: string index out of range\n",
      "Index 36: 'En el mundo están ocurriendo cosas increíbles le decía a Gabriel . Ahí mismo, al otro lado del río, '... Error: string index out of range\n",
      "Index 51: 'No importa decía Vega . Lo esencial es no perder la orientación.'... Error: string index out of range\n",
      "Index 58: 'Sus sueños terminaban frente a ese mar color de ceniza, espumoso y sucio, que no merecía los riesgos'... Error: string index out of range\n"
     ]
    }
   ],
   "source": [
    "#creaar DataFrame para alimentar el dataset (pensando en que va a ser mas rapido para el entrenamiento)\n",
    "data_path ='https://github.com/LeoBrasileo/Aprendizaje-Automatico-TP2/raw/refs/heads/main/data/marquez_cleaned.csv'  # Remove the leading slash\n",
    "data = pd.read_csv(data_path, delimiter=',')\n",
    "texto_original = data['texto_original'].tolist()\n",
    "# texto_limpio = data['texto_limpio'].tolist()\n",
    "\n",
    "puntuacion_tokens_marquez = []\n",
    "problematic_sentences = []\n",
    "\n",
    "for i in range(4,len(texto_original)):\n",
    "    try:\n",
    "        # tokens_texto_original = tokenizer.tokenize(texto_original[i])\n",
    "        texto_limpio = limpiar_string(texto_original[i])\n",
    "        tokens_texto_limpio = tokenizer.tokenize(texto_limpio)\n",
    "\n",
    "        puntuacion_tokens = asignar_puntuacion_a_tokens(instancia_original=texto_original[i],\n",
    "                                                        instancia_id=i+1,\n",
    "                                                        instancia_tokens=tokens_texto_limpio)\n",
    "        puntuacion_tokens = asignar_etiquetas_puntuacion(puntuacion_tokens)\n",
    "        puntuacion_tokens_marquez.append(puntuacion_tokens)\n",
    "    except Exception as e:\n",
    "        # Store problematic sentence info instead of breaking\n",
    "        problematic_sentences.append({\n",
    "            'index': i,\n",
    "            'original_text': texto_original[i],\n",
    "            'cleaned_text': texto_limpio if 'texto_limpio' in locals() else None,\n",
    "            'error': str(e)\n",
    "        })\n",
    "        continue\n",
    "\n",
    "\n",
    "print(f\"funcionaron: {len(puntuacion_tokens_marquez)} sentences\")\n",
    "print(f\"con problemas: {len(problematic_sentences)}\")\n",
    "\n",
    "# oraciones con problemas\n",
    "for prob in problematic_sentences[:5]:  # Show first 5 problematic sentences\n",
    "    print(f\"Index {prob['index']}: {repr(prob['original_text'][:100])}... Error: {prob['error']}\")\n",
    "\n",
    "\n",
    "# renumerar para que los ids de instancia sean consecutivos\n",
    "puntuacion_tokens_marquez_clean = []\n",
    "for new_id, tokens_list in enumerate(puntuacion_tokens_marquez):\n",
    "    tokens_list_updated = []\n",
    "    for token_dict in tokens_list:\n",
    "        token_dict_updated = token_dict.copy()\n",
    "        token_dict_updated['instancia_id'] = new_id + 1  # que empiece en 1?\n",
    "        tokens_list_updated.append(token_dict_updated)\n",
    "    puntuacion_tokens_marquez_clean.append(tokens_list_updated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py.marquez_clean import MarquezDataset, marquez_collate_fn\n",
    "\n",
    "dataset_marquez = MarquezDataset(data=puntuacion_tokens_marquez)\n",
    "loader = DataLoader(dataset_marquez, batch_size=32, shuffle=False, collate_fn=marquez_collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ejemplo de juguete con 10 samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos con muchas epochs y pocos samples, para ver si la red logra memorizarlos. Principalmente lo dejo para que lo usemos para verificar que las funciones se ejecutan bien (en este caso en particular, usando la RNN clásica, pero se puede usar en otro momento para cuando haya cambios en las redes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py.funciones_entrenamiento import entrenar_modelo\n",
    "from py.modelos.RNN_Clasica import RNN_Clasica\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'xpu:0' if torch.xpu.is_available() else device # placa intel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo de red neuronal unidireccional creado con 7883722 parámetros\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS_UNI = 150\n",
    "LEARNING_RATE_UNI = 0.0001\n",
    "EMBEDDING_DIM_UNI = 64\n",
    "HIDDEN_UNI = 128\n",
    "\n",
    "modelo_unidireccional = RNN_Clasica(hidden_size=HIDDEN_UNI, vocab_size=VOCAB_SIZE, embedding_dim=EMBEDDING_DIM_UNI)\n",
    "modelo_unidireccional = modelo_unidireccional.to(device)\n",
    "\n",
    "optimizer_unidireccional = torch.optim.Adam(modelo_unidireccional.parameters(), lr=LEARNING_RATE_UNI)\n",
    "criterion_unidireccional = nn.CrossEntropyLoss()\n",
    "\n",
    "print(f\"Modelo de red neuronal unidireccional creado con {sum(p.numel() for p in modelo_unidireccional.parameters())} parámetros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tomamos 10 samples del dataset de Gabriel García Marquez\n",
    "dataset_marquez_reduced = MarquezDataset(data=puntuacion_tokens_marquez[:10])\n",
    "\n",
    "# DataLoader con batches de tamaño 1 (dado que son solo 10 samples, pero también se podría hacer 1 solo batch de 10 secuencias, 2 batches de 5 secuencias, o tomar más samples)\n",
    "loader = DataLoader(dataset_marquez_reduced, batch_size=1, shuffle=True, collate_fn=marquez_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando entrenamiento...\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m loader \u001b[38;5;241m=\u001b[39m DataLoader(dataset_marquez_reduced, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, collate_fn\u001b[38;5;241m=\u001b[39mmarquez_collate_fn)\n\u001b[0;32m----> 3\u001b[0m _ , _ \u001b[38;5;241m=\u001b[39m \u001b[43mentrenar_modelo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodelo_unidireccional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_unidireccional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion_unidireccional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcant_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Escritorio/UBA-Exactas/2025/Aprendizaje-Automatico-TP2/py/funciones_entrenamiento.py:97\u001b[0m, in \u001b[0;36mentrenar_modelo\u001b[0;34m(modelo, datos_entrenamiento, datos_validacion, optimizador, criterio, cant_epochs, device)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(cant_epochs):\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# Entrenamiento\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mejecutar_epoch_entrenamiento\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodelo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatos_entrenamiento\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizador\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;66;03m# Validación\u001b[39;00m\n",
      "File \u001b[0;32m~/Escritorio/UBA-Exactas/2025/Aprendizaje-Automatico-TP2/py/funciones_entrenamiento.py:18\u001b[0m, in \u001b[0;36mejecutar_epoch_entrenamiento\u001b[0;34m(model, dataloader, optimizer, criterion)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Paso forward\u001b[39;00m\n\u001b[1;32m     17\u001b[0m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_ids\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 18\u001b[0m logits_punt_inic, logits_punt_final, logits_capitalizacion \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtoken_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Reshape de los logits para CE:\u001b[39;00m\n\u001b[1;32m     21\u001b[0m logits_punt_inic \u001b[38;5;241m=\u001b[39m logits_punt_inic\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, logits_punt_inic\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Escritorio/UBA-Exactas/2025/Aprendizaje-Automatico-TP2/py/modelos/RNN_Clasica.py:32\u001b[0m, in \u001b[0;36mRNN_Clasica.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     31\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(x)\n\u001b[0;32m---> 32\u001b[0m     x, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLSTM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# Cada bloque lineal produce logits (no probabilidades) para cada clase, en la tarea que le corresponde\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# No agrego softmax o algo del estilo porque luego usamos CrossEntropyLoss, que espera los logits.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     score_puntuacion_inic \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_puntuacion_inic(x)  \n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1124\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1121\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1124\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1125\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1128\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1129\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1130\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1132\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1136\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   1138\u001b[0m         batch_sizes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[1;32m   1146\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loader = DataLoader(dataset_marquez_reduced, batch_size=1, shuffle=True, collate_fn=marquez_collate_fn)\n",
    "\n",
    "_ , _ = entrenar_modelo(modelo_unidireccional, loader, loader, optimizer_unidireccional, criterion_unidireccional, cant_epochs=200, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
